import{b as U}from"./chunk-Z7GX7UB4.js";import{c as D}from"./chunk-ATBOGOG4.js";import{a as j,b as Q,c as H,d as W,e as $}from"./chunk-B7HKOD5H.js";import{b as B,d as F}from"./chunk-5PXSGVCU.js";import{a as K}from"./chunk-RFEADQEJ.js";import{a as G}from"./chunk-W6XK6A7R.js";import"./chunk-OLOMOLV6.js";import"./chunk-NBA2CVHA.js";import{b as N,c as q}from"./chunk-JBYAIWDU.js";import"./chunk-5JGVW3ZI.js";import"./chunk-QIUC4OF3.js";import"./chunk-AFX4PMBX.js";import{k}from"./chunk-L6UVA74T.js";import{$b as c,Ab as v,Bb as a,Cb as o,Db as R,Eb as y,Fb as T,Gb as w,Nb as O,Ob as L,Qb as P,Rb as I,Sb as A,Ta as d,_b as r,ab as M,gb as p,hc as z,qa as E,xb as u,yb as g,zb as h}from"./chunk-FNS6TF3S.js";import"./chunk-UUTQQLSI.js";var Z=["canvas"],ee=["*"],f=class s{node_size=3;node_color="#ffffff";node_count=120;node_speed=.5;edge_color="#fffff0";canvasRef;ctx;mouse=E({x:0,y:0});particles=[];count=this.node_count;constructor(){requestAnimationFrame(()=>this.init())}init(){let n=this.canvasRef.nativeElement,e=()=>{n.width=n.clientWidth,n.height=n.clientHeight};e(),window.addEventListener("resize",e),this.ctx=n.getContext("2d"),window.addEventListener("mousemove",i=>{let l=this.canvasRef.nativeElement.getBoundingClientRect();this.mouse.set({x:i.clientX-l.left,y:i.clientY-l.top})});for(let i=0;i<this.count;i++)this.particles.push({x:Math.random()*n.width,y:Math.random()*n.height,vx:(Math.random()-.5)*this.node_speed,vy:(Math.random()-.5)*this.node_speed});requestAnimationFrame(()=>this.loop())}loop(){let n=this.canvasRef.nativeElement,e=this.ctx,{width:i,height:l}=n;e.clearRect(0,0,i,l);for(let t of this.particles)t.x+=t.vx,t.y+=t.vy,(t.x<0||t.x>i)&&(t.vx*=-1),(t.y<0||t.y>l)&&(t.vy*=-1);e.fillStyle=this.node_color;for(let t of this.particles)e.beginPath(),e.arc(t.x,t.y,this.node_size,0,Math.PI*2),e.fill();e.strokeStyle=this.edge_color;let _=this.mouse();for(let t of this.particles){let b=t.x-_.x,C=t.y-_.y;if(!(Math.sqrt(b*b+C*C)>180))for(let m of this.particles){let x=t.x-m.x,S=t.y-m.y;Math.sqrt(x*x+S*S)<200&&(e.beginPath(),e.moveTo(t.x,t.y),e.lineTo(m.x,m.y),e.stroke())}}requestAnimationFrame(()=>this.loop())}static \u0275fac=function(e){return new(e||s)};static \u0275cmp=p({type:s,selectors:[["app-constellation"]],viewQuery:function(e,i){if(e&1&&P(Z,7),e&2){let l;I(l=A())&&(i.canvasRef=l.first)}},inputs:{node_size:"node_size",node_color:"node_color",node_count:"node_count",node_speed:"node_speed",edge_color:"edge_color"},ngContentSelectors:ee,decls:5,vars:0,consts:[["canvas",""],[1,"constellation-wrapper"],[1,"constellation-canvas"],[1,"constellation-overlay"]],template:function(e,i){e&1&&(O(),y(0,"div",1),w(1,"canvas",2,0),y(3,"div",3),L(4),T()())},styles:[".constellation-wrapper[_ngcontent-%COMP%]{position:relative;width:100%;height:100%;display:block}.constellation-canvas[_ngcontent-%COMP%]{position:absolute;inset:0;width:100%;height:100%;display:block}.constellation-overlay[_ngcontent-%COMP%]{position:relative;z-index:10;pointer-events:auto}"]})};var V={"coral-1":"#ff7d86","coral-2":"#ff9ba2","coral-3":"#ffbdc2","coral-4":"#ffdddf","coral-5":"#fff1f1","coral-g1":"#bce354","coral-g2":"#8add1a"};function te(s,n){if(s&1&&(a(0,"mat-card",11)(1,"div",16)(2,"mat-icon"),r(3),o()(),a(4,"mat-card-header",17)(5,"mat-card-title",18),r(6),o()(),a(7,"mat-card-content")(8,"p",19),r(9),o()()()),s&2){let e=n.$implicit;d(3),c(e.icon),d(3),c(e.title),d(3),c(e.description)}}function ne(s,n){if(s&1&&(a(0,"div")(1,"div",20),r(2),o(),a(3,"div",19),r(4),o()()),s&2){let e=n.$implicit;d(2),c(e.title),d(2),c(e.content)}}var X=class s{constructor(n){this.themeService=n}nodes=[{id:"node1",name:"EEG",x:0,y:0,input:!1,output:!0,input_args:["ch_names","sfreq"],output_args:["aux"],description:"EEG signal input node"},{id:"node2",name:"Normalization",x:350,y:100,input:!0,output:!0,input_args:["aux"],output_args:["aux_norm"],description:"Normalizes input signals"},{id:"node3",name:"EEGNet",x:700,y:200,input:!0,output:!1,input_args:["aux_norm"],description:"Neural network for EEG processing"}];edges=[{from:"node1.output",to:"node2.input"},{from:"node2.output",to:"node3.input"}];edgesArgs=[];node_color=z(()=>this.themeService.mode()==="light"?this.themeService.getFromTheme("--mat-sys-surface-container-low"):this.themeService.getFromTheme("--mat-sys-surface-container-low"));COLORS_LOTUS=V;FEATURE_GRID=[{title:"Integrated Signal Acquisition",description:"Connect EEG/EMG/ECoG hardware and stream high-fidelity data instantly.",icon:"sensors"},{title:"Real-Time Pipelines",description:"Modular DSP/ML nodes for filtering, feature extraction, and inference.",icon:"hub"},{title:"Stimulus Engine (CtenoLab)",description:"Millisecond-accurate presentation synchronized with acquisition.",icon:"bolt"},{title:"Session & Trial Management",description:"Structured storage, metadata integrity, reproducibility, and export workflows.",icon:"folder_open"}];USE_CASES=[{title:"Use Cases",content:""},{title:"BCI Research",content:"Rapid prototyping of classifiers, motor-imagery paradigms, and cognitive tasks."},{title:"Cognitive Neuroscience",content:"Controlled experiments with synchronized stimuli and fully reproducible pipelines."},{title:"Clinical & Exploratory Workflows",content:"Structured monitoring, annotations, and data export for analytical pipelines."}];static \u0275fac=function(e){return new(e||s)(M(G))};static \u0275cmp=p({type:s,selectors:[["app-landing"]],decls:30,vars:11,consts:[[3,"node_color","edge_color","node_size","node_count","node_speed"],[1,"container-10","overflow-x-hidden","margin-top-5vh"],[1,"grid-responsive-auto"],[1,"flex-column"],[1,"mat-font-display-lg","clamp"],[1,"mat-font-headline-lg","clamp","justify"],[1,"container-10","grid-responsive-2","button-big","margin-top-extra-large","margin-bottom-large"],["matButton","filled","routerLink","/app"],["matButton","outlined","routerLink","/pricing"],[3,"nodes","edges","edgesArgs","panScroll","useTiles","toolbar"],[1,"container-20","margin-top-10vh"],["appearance","outlined",1,"example-card"],[1,"container-10","margin-top-15vh"],[1,"grid-responsive-auto","grid-1-3"],[1,"medium","mat-font-headline-sm","clamp","margin-bottom-medium"],[1,"mat-font-headline-md","clamp"],[1,"justify-center","margin-top-large","landing-icon"],[1,"justify-center"],[1,"medium","mat-font-headline-sm","clamp"],[1,"mat-font-title-lg","clamp"],[1,"medium","mat-font-headline-sm","clamp","margin-bottom-medium","padding-top-medium"]],template:function(e,i){e&1&&(a(0,"app-constellation",0)(1,"div",1)(2,"div",2)(3,"div",3)(4,"span",4),r(5,"Unified Neurotechnology Platform for Real-Time Acquisition, Processing, and Experiment Design."),o(),a(6,"span",5),r(7,"A single environment for electrophysiological recording, stimulus presentation, synchronized events, and advanced BCI pipelines."),o(),a(8,"div",6)(9,"a",7),r(10,"Get Started"),o(),a(11,"a",8),r(12,"Pricing"),o()()(),R(13,"app-pipeline-controller",9),o()(),a(14,"div",10)(15,"div",2),g(16,te,10,3,"mat-card",11,u),o()(),a(18,"div",12)(19,"div",13)(20,"div")(21,"div",14),r(22,"System Overview"),o()(),a(23,"div")(24,"div",15),r(25,"Cnida unifies acquisition hardware, browser-based visualization, experiment control, and machine-learning pipelines under a single architecture\u2014no fragmented toolchains. "),o()()()(),a(26,"div",12)(27,"div",2),g(28,ne,5,2,"div",null,u),o()()()),e&2&&(v("node_color",i.node_color())("edge_color",i.node_color())("node_size",10)("node_count",100)("node_speed",.3),d(13),v("nodes",i.nodes)("edges",i.edges)("edgesArgs",i.edgesArgs)("panScroll",!1)("useTiles",!1)("toolbar",!1),d(3),h(i.FEATURE_GRID),d(12),h(i.USE_CASES))},dependencies:[k,D,U,F,B,f,$,j,H,W,Q,q,N,K],styles:["[_nghost-%COMP%]{--mat-toolbar-standard-height: var(--toolbar-height);--mat-toolbar-standard-height: 96px;--mat-toolbar-mobile-height: 96px}.button-big[_ngcontent-%COMP%]{scale:1.4}.landing-icon[_ngcontent-%COMP%]{color:var(--mat-sys-primary)}.landing-icon[_ngcontent-%COMP%]   mat-icon[_ngcontent-%COMP%]{font-size:4rem;height:4rem;width:4rem}.hero_image[_ngcontent-%COMP%]{width:100%;background-size:contain;background-repeat:no-repeat;background-position:center}"]})};export{X as LandingComponent};
